{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3287ac8",
   "metadata": {},
   "source": [
    "# Case Study Analysis\n",
    "\n",
    "Amazon Product Classification - DATA304 Final Project\n",
    "\n",
    "**Objective:** Detailed analysis of individual predictions, error patterns, and model behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbb259",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "\n",
    "# Project imports\n",
    "from src.data_preprocessing import DataLoader\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Directories\n",
    "predictions_dir = Path('../results/predictions')\n",
    "fig_dir = Path('../results/images/case_study')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"              CASE STUDY ANALYSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"✓ Images will be saved to: {fig_dir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = DataLoader(data_dir='../data/raw/Amazon_products')\n",
    "data_loader.load_all()\n",
    "\n",
    "print(f\"✓ Loaded {data_loader.num_classes} classes\")\n",
    "print(f\"✓ Test samples: {len(data_loader.test_corpus)}\")\n",
    "\n",
    "# Load class names\n",
    "class_names = {}\n",
    "with open('../data/raw/Amazon_products/classes.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if '\\t' in line:\n",
    "            class_id, class_name = line.strip().split('\\t', 1)\n",
    "            class_names[int(class_id)] = class_name\n",
    "\n",
    "print(f\"✓ Loaded {len(class_names)} class names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf076a",
   "metadata": {},
   "source": [
    "## 1. Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load latest prediction file\n",
    "MODEL_NAME = 'baseline'  # Change to analyze different models\n",
    "\n",
    "pred_files = list(predictions_dir.glob(f'{MODEL_NAME}_*.pkl'))\n",
    "\n",
    "if pred_files:\n",
    "    # Load most recent\n",
    "    pred_file = sorted(pred_files)[-1]\n",
    "    print(f\"Loading: {pred_file.name}\\n\")\n",
    "    \n",
    "    with open(pred_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    pids = results['pids']\n",
    "    predictions = results['predictions']\n",
    "    probabilities = results['probabilities']\n",
    "    \n",
    "    print(f\"✓ Loaded predictions for {len(pids)} samples\")\n",
    "    print(f\"✓ Model: {results.get('model_name', 'unknown')}\")\n",
    "    print(f\"✓ Threshold: {results.get('threshold', 0.5)}\")\n",
    "else:\n",
    "    print(f\"⚠️  No prediction files found for {MODEL_NAME}\")\n",
    "    print(f\"   Run predict.py first!\")\n",
    "    pids, predictions, probabilities = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaac378",
   "metadata": {},
   "source": [
    "## 2. Prediction Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Extract max confidence per sample\n",
    "    max_confidences = []\n",
    "    avg_confidences = []\n",
    "    \n",
    "    for i, pred_classes in enumerate(predictions):\n",
    "        if len(pred_classes) > 0:\n",
    "            # Get probabilities for predicted classes\n",
    "            class_probs = [probabilities[i][c] for c in pred_classes]\n",
    "            max_confidences.append(max(class_probs))\n",
    "            avg_confidences.append(np.mean(class_probs))\n",
    "        else:\n",
    "            max_confidences.append(0.0)\n",
    "            avg_confidences.append(0.0)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Max confidence distribution\n",
    "    axes[0].hist(max_confidences, bins=50, alpha=0.8, edgecolor='black', color='#2E86AB')\n",
    "    axes[0].axvline(np.mean(max_confidences), color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {np.mean(max_confidences):.3f}')\n",
    "    axes[0].set_xlabel('Max Confidence Score', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_ylabel('Frequency', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_title(f'{MODEL_NAME.upper()} - Max Confidence Distribution', \n",
    "                     fontsize=15, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Average confidence distribution\n",
    "    axes[1].hist(avg_confidences, bins=50, alpha=0.8, edgecolor='black', color='#F18F01')\n",
    "    axes[1].axvline(np.mean(avg_confidences), color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Mean: {np.mean(avg_confidences):.3f}')\n",
    "    axes[1].set_xlabel('Average Confidence Score', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontsize=13, fontweight='bold')\n",
    "    axes[1].set_title(f'{MODEL_NAME.upper()} - Average Confidence Distribution', \n",
    "                     fontsize=15, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved: {fig_dir / 'confidence_distribution.png'}\")\n",
    "    print(f\"\\nConfidence Statistics:\")\n",
    "    print(f\"  Max confidence - Mean: {np.mean(max_confidences):.3f}, Std: {np.std(max_confidences):.3f}\")\n",
    "    print(f\"  Avg confidence - Mean: {np.mean(avg_confidences):.3f}, Std: {np.std(avg_confidences):.3f}\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee39e3a",
   "metadata": {},
   "source": [
    "## 3. Example Predictions - High Confidence Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Find high confidence examples\n",
    "    high_conf_indices = np.argsort(max_confidences)[-5:][::-1]  # Top 5\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"           HIGH CONFIDENCE PREDICTIONS (Top 5)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for rank, idx in enumerate(high_conf_indices, 1):\n",
    "        pid = pids[idx]\n",
    "        text = data_loader.test_corpus[pid]\n",
    "        pred_classes = predictions[idx]\n",
    "        \n",
    "        print(f\"[Example {rank}] Document ID: {pid}\")\n",
    "        print(f\"Max Confidence: {max_confidences[idx]:.4f}\")\n",
    "        print(f\"\\nText (first 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"\\nPredicted Classes ({len(pred_classes)}):\")\n",
    "        \n",
    "        for cls_id in pred_classes[:5]:  # Show top 5 classes\n",
    "            conf = probabilities[idx][cls_id]\n",
    "            cls_name = class_names.get(cls_id, f\"Unknown-{cls_id}\")\n",
    "            print(f\"  - Class {cls_id}: {cls_name} (confidence: {conf:.4f})\")\n",
    "        \n",
    "        if len(pred_classes) > 5:\n",
    "            print(f\"  ... and {len(pred_classes)-5} more classes\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00954",
   "metadata": {},
   "source": [
    "## 4. Example Predictions - Low Confidence Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfea3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Find low confidence examples (but with predictions)\n",
    "    valid_indices = [i for i, p in enumerate(predictions) if len(p) > 0]\n",
    "    valid_confidences = [max_confidences[i] for i in valid_indices]\n",
    "    low_conf_indices = [valid_indices[i] for i in np.argsort(valid_confidences)[:5]]  # Bottom 5\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"           LOW CONFIDENCE PREDICTIONS (Bottom 5)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for rank, idx in enumerate(low_conf_indices, 1):\n",
    "        pid = pids[idx]\n",
    "        text = data_loader.test_corpus[pid]\n",
    "        pred_classes = predictions[idx]\n",
    "        \n",
    "        print(f\"[Example {rank}] Document ID: {pid}\")\n",
    "        print(f\"Max Confidence: {max_confidences[idx]:.4f}\")\n",
    "        print(f\"\\nText (first 200 chars):\")\n",
    "        print(f\"  {text[:200]}...\")\n",
    "        print(f\"\\nPredicted Classes ({len(pred_classes)}):\")\n",
    "        \n",
    "        for cls_id in pred_classes[:5]:\n",
    "            conf = probabilities[idx][cls_id]\n",
    "            cls_name = class_names.get(cls_id, f\"Unknown-{cls_id}\")\n",
    "            print(f\"  - Class {cls_id}: {cls_name} (confidence: {conf:.4f})\")\n",
    "        \n",
    "        if len(pred_classes) > 5:\n",
    "            print(f\"  ... and {len(pred_classes)-5} more classes\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a704b1",
   "metadata": {},
   "source": [
    "## 5. Visualization - Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f98084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Visualize top 10 predictions with confidence bars\n",
    "    sample_indices = high_conf_indices[:3].tolist() + low_conf_indices[:2].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(len(sample_indices), 1, figsize=(14, 4*len(sample_indices)))\n",
    "    if len(sample_indices) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax_idx, idx in enumerate(sample_indices):\n",
    "        pid = pids[idx]\n",
    "        pred_classes = predictions[idx][:10]  # Top 10 classes\n",
    "        confidences = [probabilities[idx][c] for c in pred_classes]\n",
    "        labels = [f\"C{c}: {class_names.get(c, 'Unknown')[:30]}\" for c in pred_classes]\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        y_pos = np.arange(len(labels))\n",
    "        colors = plt.cm.RdYlGn(np.array(confidences))\n",
    "        \n",
    "        axes[ax_idx].barh(y_pos, confidences, color=colors, edgecolor='black', alpha=0.8)\n",
    "        axes[ax_idx].set_yticks(y_pos)\n",
    "        axes[ax_idx].set_yticklabels(labels, fontsize=9)\n",
    "        axes[ax_idx].set_xlabel('Confidence Score', fontsize=11, fontweight='bold')\n",
    "        axes[ax_idx].set_title(f'Doc {pid} - Text: \"{data_loader.test_corpus[pid][:60]}...\"', \n",
    "                              fontsize=12, fontweight='bold')\n",
    "        axes[ax_idx].set_xlim(0, 1.0)\n",
    "        axes[ax_idx].grid(axis='x', alpha=0.3)\n",
    "        axes[ax_idx].invert_yaxis()\n",
    "        \n",
    "        # Add confidence values\n",
    "        for i, (conf, label) in enumerate(zip(confidences, labels)):\n",
    "            axes[ax_idx].text(conf + 0.02, i, f'{conf:.3f}', \n",
    "                             va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'example_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved: {fig_dir / 'example_predictions.png'}\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bbd63d",
   "metadata": {},
   "source": [
    "## 6. Hierarchy Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Build hierarchy graph\n",
    "    G = nx.DiGraph()\n",
    "    for parent, child in data_loader.hierarchy:\n",
    "        G.add_edge(parent, child)\n",
    "    \n",
    "    # Check for hierarchy violations\n",
    "    violations = []\n",
    "    total_pairs = 0\n",
    "    \n",
    "    for idx, pred_classes in enumerate(predictions):\n",
    "        for child in pred_classes:\n",
    "            # Check if all ancestors are also predicted\n",
    "            if child in G:\n",
    "                ancestors = set()\n",
    "                for node in nx.ancestors(G, child):\n",
    "                    ancestors.add(node)\n",
    "                \n",
    "                for ancestor in ancestors:\n",
    "                    total_pairs += 1\n",
    "                    if ancestor not in pred_classes:\n",
    "                        violations.append({\n",
    "                            'doc_id': pids[idx],\n",
    "                            'child': child,\n",
    "                            'missing_ancestor': ancestor\n",
    "                        })\n",
    "    \n",
    "    violation_rate = len(violations) / total_pairs if total_pairs > 0 else 0\n",
    "    \n",
    "    print(f\"Hierarchy Consistency Analysis:\")\n",
    "    print(f\"  Total parent-child pairs checked: {total_pairs}\")\n",
    "    print(f\"  Hierarchy violations: {len(violations)}\")\n",
    "    print(f\"  Violation rate: {violation_rate:.2%}\")\n",
    "    \n",
    "    if violations:\n",
    "        print(f\"\\nExample violations (first 5):\")\n",
    "        for i, v in enumerate(violations[:5], 1):\n",
    "            child_name = class_names.get(v['child'], f\"Unknown-{v['child']}\")\n",
    "            parent_name = class_names.get(v['missing_ancestor'], f\"Unknown-{v['missing_ancestor']}\")\n",
    "            print(f\"  {i}. Doc {v['doc_id']}: Predicted '{child_name}' but missing parent '{parent_name}'\")\n",
    "    \n",
    "    # Visualize violation rate\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    categories = ['Consistent', 'Violations']\n",
    "    values = [total_pairs - len(violations), len(violations)]\n",
    "    colors = ['#2E86AB', '#E76F51']\n",
    "    \n",
    "    bars = ax.bar(categories, values, color=colors, alpha=0.8, edgecolor='black', width=0.5)\n",
    "    ax.set_ylabel('Number of Predictions', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'{MODEL_NAME.upper()} - Hierarchy Consistency', fontsize=15, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels and percentages\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        pct = val / total_pairs * 100 if total_pairs > 0 else 0\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "               f'{val}\\n({pct:.1f}%)', ha='center', va='bottom', \n",
    "               fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'hierarchy_violations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Saved: {fig_dir / 'hierarchy_violations.png'}\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f357",
   "metadata": {},
   "source": [
    "## 7. Error Analysis - Multi-Label Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None:\n",
    "    # Analyze prediction patterns\n",
    "    labels_per_sample = [len(p) for p in predictions]\n",
    "    no_prediction_count = sum(1 for p in predictions if len(p) == 0)\n",
    "    \n",
    "    # Group by number of labels\n",
    "    label_groups = {\n",
    "        '0 labels': sum(1 for l in labels_per_sample if l == 0),\n",
    "        '1 label': sum(1 for l in labels_per_sample if l == 1),\n",
    "        '2-3 labels': sum(1 for l in labels_per_sample if 2 <= l <= 3),\n",
    "        '4-5 labels': sum(1 for l in labels_per_sample if 4 <= l <= 5),\n",
    "        '6-10 labels': sum(1 for l in labels_per_sample if 6 <= l <= 10),\n",
    "        '11+ labels': sum(1 for l in labels_per_sample if l > 10)\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Bar chart of label groups\n",
    "    groups = list(label_groups.keys())\n",
    "    counts = list(label_groups.values())\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(groups)))\n",
    "    \n",
    "    bars = axes[0].bar(range(len(groups)), counts, color=colors, alpha=0.8, edgecolor='black')\n",
    "    axes[0].set_xticks(range(len(groups)))\n",
    "    axes[0].set_xticklabels(groups, rotation=15, ha='right')\n",
    "    axes[0].set_ylabel('Number of Samples', fontsize=13, fontweight='bold')\n",
    "    axes[0].set_title(f'{MODEL_NAME.upper()} - Prediction Pattern Distribution', \n",
    "                     fontsize=15, fontweight='bold')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        pct = count / len(predictions) * 100\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Confidence vs number of labels\n",
    "    labels_with_conf = [(l, max_confidences[i]) for i, l in enumerate(labels_per_sample) if l > 0]\n",
    "    if labels_with_conf:\n",
    "        label_counts, confs = zip(*labels_with_conf)\n",
    "        \n",
    "        axes[1].scatter(label_counts, confs, alpha=0.5, s=20, color='#2E86AB')\n",
    "        axes[1].set_xlabel('Number of Predicted Labels', fontsize=13, fontweight='bold')\n",
    "        axes[1].set_ylabel('Max Confidence', fontsize=13, fontweight='bold')\n",
    "        axes[1].set_title('Confidence vs Number of Labels', fontsize=15, fontweight='bold')\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(label_counts, confs, 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(min(label_counts), max(label_counts), 100)\n",
    "        axes[1].plot(x_line, p(x_line), \"r--\", linewidth=2, alpha=0.8, label='Trend')\n",
    "        axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved: {fig_dir / 'error_analysis.png'}\")\n",
    "    print(f\"\\nMulti-Label Statistics:\")\n",
    "    print(f\"  Samples with no predictions: {no_prediction_count} ({no_prediction_count/len(predictions)*100:.1f}%)\")\n",
    "    print(f\"  Average labels per sample: {np.mean(labels_per_sample):.2f}\")\n",
    "    print(f\"  Median: {np.median(labels_per_sample):.0f}\")\n",
    "    print(f\"  Max: {max(labels_per_sample)}\")\n",
    "else:\n",
    "    print(\"⚠️  No predictions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0941612",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ All case study visualizations saved to: `results/images/case_study/`\n",
    "\n",
    "**Generated Files:**\n",
    "- `confidence_distribution.png` - Max and average confidence score distributions\n",
    "- `example_predictions.png` - Detailed visualization of high/low confidence examples\n",
    "- `hierarchy_violations.png` - Hierarchy consistency analysis\n",
    "- `error_analysis.png` - Multi-label prediction patterns and confidence trends\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "**Confidence Patterns:**\n",
    "- High confidence predictions: Model is certain about specific classes\n",
    "- Low confidence predictions: Ambiguous cases or borderline classifications\n",
    "- Average confidence gives overall model certainty\n",
    "\n",
    "**Prediction Quality:**\n",
    "- Examples show how model interprets text features\n",
    "- Class names reveal if predictions make semantic sense\n",
    "- Multiple labels indicate product category complexity\n",
    "\n",
    "**Hierarchy Consistency:**\n",
    "- Measures if child classes have parent classes predicted\n",
    "- Violations indicate potential model improvements needed\n",
    "- Useful for hierarchical loss function evaluation\n",
    "\n",
    "**Error Patterns:**\n",
    "- Samples with no predictions: Threshold too strict or unclear text\n",
    "- Samples with many predictions: General products or threshold too loose\n",
    "- Confidence vs label count correlation reveals model behavior\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **High Confidence Cases**: Use as training examples for future iterations\n",
    "2. **Low Confidence Cases**: Review for data quality or ambiguity issues\n",
    "3. **Hierarchy Violations**: Consider hierarchical loss constraints\n",
    "4. **No Predictions**: Adjust threshold or improve silver labeling\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps:\n",
    "1. Analyze specific failure cases manually\n",
    "2. Adjust confidence threshold based on precision-recall trade-off\n",
    "3. Improve hierarchy constraint enforcement\n",
    "4. Collect human annotations for ambiguous cases"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
