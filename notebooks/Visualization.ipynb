{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Figure directory\n",
    "fig_dir = Path('../report/figures')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f05b9",
   "metadata": {},
   "source": [
    "## 1. Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "models_dir = Path('../models')\n",
    "\n",
    "# Example: Load BERT baseline\n",
    "with open(models_dir / 'baseline_bert_hierarchical' / 'training_history.json') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['epochs'], history['train_loss'], marker='o', linewidth=2, label='Training Loss')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / 'training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Saved: {fig_dir / 'training_loss.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835f18a",
   "metadata": {},
   "source": [
    "## 2. Multiple Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e510af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple models\n",
    "model_configs = [\n",
    "    ('baseline_bert_hierarchical', 'BERT + Hierarchical Loss'),\n",
    "    ('gcn_hierarchical', 'GCN + Hierarchical Loss'),\n",
    "    ('gat_hierarchical', 'GAT + Hierarchical Loss'),\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for model_dir, label in model_configs:\n",
    "    history_path = models_dir / model_dir / 'training_history.json'\n",
    "    if history_path.exists():\n",
    "        with open(history_path) as f:\n",
    "            history = json.load(f)\n",
    "        plt.plot(history['epochs'], history['train_loss'], marker='o', linewidth=2, label=label)\n",
    "\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Training Loss', fontsize=12)\n",
    "plt.title('Model Comparison: Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / 'model_comparison_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Saved: {fig_dir / 'model_comparison_loss.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b92e38",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6658bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint metrics (from checkpoint files)\n",
    "results = []\n",
    "\n",
    "for model_dir, label in model_configs:\n",
    "    checkpoint_path = models_dir / model_dir / 'best_model.pt'\n",
    "    if checkpoint_path.exists():\n",
    "        # You would load actual metrics from evaluation\n",
    "        # For now, create sample data structure\n",
    "        results.append({\n",
    "            'Model': label,\n",
    "            'Micro F1': 0.0,  # Replace with actual metrics\n",
    "            'Macro F1': 0.0,\n",
    "            'Precision': 0.0,\n",
    "            'Recall': 0.0,\n",
    "            'Final Loss': 0.0\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(fig_dir.parent / 'results_table.csv', index=False)\n",
    "print(f\"\\n✓ Saved: {fig_dir.parent / 'results_table.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35867b92",
   "metadata": {},
   "source": [
    "## 4. Metrics Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8396c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics comparison\n",
    "metrics = ['Micro F1', 'Macro F1', 'Precision', 'Recall']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    ax.bar(df['Model'], df[metric], alpha=0.7, edgecolor='black')\n",
    "    ax.set_ylabel(metric, fontsize=11)\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / 'metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Saved: {fig_dir / 'metrics_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab5acd",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix / Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Label distribution from predictions\n",
    "# Load predictions pickle file\n",
    "import pickle\n",
    "\n",
    "pred_file = Path('../predictions/test_predictions.pkl')\n",
    "if pred_file.exists():\n",
    "    with open(pred_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    predictions = results['predictions']\n",
    "    \n",
    "    # Count labels per sample\n",
    "    label_counts = [len(p) for p in predictions]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(label_counts, bins=range(1, max(label_counts)+2), alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Number of Labels per Sample', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title('Predicted Label Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved: {fig_dir / 'label_distribution.png'}\")\n",
    "    print(f\"Average labels per sample: {np.mean(label_counts):.2f}\")\n",
    "else:\n",
    "    print(f\"Prediction file not found: {pred_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162d6a1",
   "metadata": {},
   "source": [
    "## 6. Top Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dde925",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_file.exists():\n",
    "    # Count class frequencies\n",
    "    from collections import Counter\n",
    "    \n",
    "    all_labels = [label for pred in predictions for label in pred]\n",
    "    label_freq = Counter(all_labels)\n",
    "    top_classes = label_freq.most_common(20)\n",
    "    \n",
    "    classes, counts = zip(*top_classes)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(len(classes)), counts, alpha=0.7, edgecolor='black')\n",
    "    plt.yticks(range(len(classes)), [f'Class {c}' for c in classes])\n",
    "    plt.xlabel('Frequency', fontsize=12)\n",
    "    plt.ylabel('Class', fontsize=12)\n",
    "    plt.title('Top 20 Predicted Classes', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'top_classes.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved: {fig_dir / 'top_classes.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5e6e2",
   "metadata": {},
   "source": [
    "## 7. Export All Figures\n",
    "\n",
    "모든 그림이 `report/figures/` 폴더에 저장되었습니다.\n",
    "\n",
    "**생성된 파일:**\n",
    "- `training_loss.png`: 단일 모델 학습 곡선\n",
    "- `model_comparison_loss.png`: 여러 모델 비교\n",
    "- `metrics_comparison.png`: 성능 지표 비교\n",
    "- `label_distribution.png`: 예측 레이블 분포\n",
    "- `top_classes.png`: 가장 많이 예측된 클래스\n",
    "- `../results_table.csv`: 성능 비교 표 (CSV)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
