# ğŸ›ï¸ Amazon Hierarchical Product Classification

**í•™ë²ˆ:** 2020320135 | **ê³¼ëª©:** DATA304

---

## ğŸ“‹ ê°œìš”

Amazon ìƒí’ˆì„ 531ê°œ í´ë˜ìŠ¤ë¡œ ìë™ ë¶„ë¥˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ë°©ë²•**: Silver Label ìƒì„± â†’ BCE í•™ìŠµ â†’ Self-Training (KLD)  
**íŠ¹ì§•**: ë ˆì´ë¸” ì—†ì´ë„ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

**í•µì‹¬ ë””ë ‰í† ë¦¬:**
- `config/`: ì‹¤í—˜ ì„¤ì • (ë‹¨ì¼ YAML íŒŒì¼)
- `data/`: ì›ë³¸ â†’ ì¤‘ê°„ ì²˜ë¦¬ ê²°ê³¼
  - `raw/Amazon_products/`: ì›ë³¸ ë°ì´í„° (train/test corpus)
  - `intermediate/`: ì „ì²˜ë¦¬ ê²°ê³¼ (silver labels)
  - `models/`: í•™ìŠµëœ ëª¨ë¸ ì €ì¥ (.pt, .json)
- `scripts/`: ì‹¤í–‰ ì§„ì…ì  (config ê¸°ë°˜)
- `results/`: ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ ì €ì¥
  - `training/`: í•™ìŠµ ì‹œê°í™” (loss curves)
  - `evaluation/`: í‰ê°€ ë©”íŠ¸ë¦­ ë° ì‹œê°í™”
  - `images/`: Jupyter ë…¸íŠ¸ë¶ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
  - `predictions/`: ì˜ˆì¸¡ ê²°ê³¼ (pkl)
  - `submissions/`: ì œì¶œ íŒŒì¼ (csv)
- `src/`: ëª¨ë“  ì†ŒìŠ¤ ì½”ë“œ (ëª¨ë¸, í•™ìŠµ, ì¶”ë¡ , í‰ê°€)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3 -m venv data304
source data304/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

**í•„ìš”**: Python 3.10+, 16GB RAM, 10GB ì €ì¥ê³µê°„

### 2. ì „ì²´ ì‹¤í–‰ (í•œ ë²ˆì—)

```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ (ìµœì´ˆ 1íšŒ)
chmod +x run.sh

# ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰
./run.sh
```

**ì†Œìš” ì‹œê°„**: CPU 12-16ì‹œê°„, GPU 3-4ì‹œê°„

### 3. ë‹¨ê³„ë³„ ì‹¤í–‰ (ì„ íƒ)

```bash
# 1. ë°ì´í„° ì „ì²˜ë¦¬
python3 src/data_preprocessing.py

# 2. Silver Label ìƒì„± (30-45ë¶„)
python3 scripts/generate_labels.py

# 3. ëª¨ë¸ í•™ìŠµ (Stage 1: BCE â†’ Stage 2: Self-Training)
python3 scripts/train_with_config.py

# 4. ì˜ˆì¸¡ ìƒì„±
python3 src/inference/predict.py \
  --model_path data/output/models/baseline/best_model.pt \
  --model_name baseline

# 5. ì œì¶œ íŒŒì¼ ìƒì„±
python3 scripts/generate_submission.py \
  --predictions results/predictions/baseline_*.csv \
  --output results/submissions/2020320135_baseline.csv
```

**í•™ìŠµ ì¤‘ ìë™ ìƒì„±**:
- `data/output/models/baseline/best_model.pt` - ìµœì¢… ëª¨ë¸
- `data/output/models/baseline/training_history.json` - í•™ìŠµ ê¸°ë¡
- `results/training/baseline/*.png` - í•™ìŠµ ì‹œê°í™” (loss curves)

**ìµœì¢… ì¶œë ¥**: `results/submissions/2020320135_baseline.csv` (ì œì¶œìš©)

---

### 4. ëª¨ë¸ í‰ê°€ (ì„ íƒ)

```bash
# ë‹¨ë… ì‹¤í–‰
python3 src/evaluation/evaluate_model.py \
  --model_path data/models/baseline/best_model.pt \
  --model_type baseline \
  --save_predictions

# ë˜ëŠ” run.shë¡œ ì‹¤í–‰ (Step 3.5)
./run.sh --step 3.5
```

**í‰ê°€ ë°ì´í„°**: Test set (19,658 samples) with silver labels (pseudo ground truth)  
**ì£¼ì˜**: Silver labelì„ ì •ë‹µìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ì‹¤ì œ ì„±ëŠ¥ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì¶œë ¥ ìœ„ì¹˜**: `results/evaluation/{model_type}/`

**í‰ê°€ ë©”íŠ¸ë¦­** (Multi-Label Classification):
- **Micro F1/Precision/Recall**: ì „ì²´ ì˜ˆì¸¡ì˜ ì •í™•ë„ (í´ë˜ìŠ¤ ë¹ˆë„ ê°€ì¤‘)
- **Macro F1/Precision/Recall**: í´ë˜ìŠ¤ë³„ í‰ê·  (í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬´ì‹œ)
- **Samples F1**: ìƒ˜í”Œë³„ F1 í‰ê·  (ë¬¸ì„œ ë‹¨ìœ„ ì„±ëŠ¥)
- **Top-k Accuracy**: ìƒìœ„ kê°œ ì˜ˆì¸¡ ì¤‘ ì •ë‹µ í¬í•¨ ë¹„ìœ¨ (k=3, 5)
- **Exact Match Ratio**: ëª¨ë“  ë ˆì´ë¸”ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨

**ìƒì„± íŒŒì¼** (6ê°œ ì‹œê°í™”):
1. `eval_{model_name}_metrics.json` - ìƒì„¸ ë©”íŠ¸ë¦­ (JSON)
2. `eval_{model_name}_confidence_distribution.png` - ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬ (positive/negative)
3. `eval_{model_name}_labels_per_sample_distribution.png` - ìƒ˜í”Œë‹¹ ë ˆì´ë¸” ìˆ˜ ë¶„í¬
4. `eval_{model_name}_metrics.png` - ì „ì²´ ë©”íŠ¸ë¦­ ë§‰ëŒ€ ê·¸ë˜í”„
5. `eval_{model_name}_f1_precision_recall.png` - F1/Precision/Recall ë¹„êµ
6. `eval_{model_name}_topk_accuracy.png` - Top-3/Top-5/Exact Match ì •í™•ë„
7. `eval_{model_name}_per_class_performance.png` - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (ìƒìœ„/í•˜ìœ„ 10ê°œ)

**ì‹¤ì „ ì„±ëŠ¥**: Kaggle ì œì¶œ í›„ ì‹¤ì œ ì„±ëŠ¥ í™•ì¸ í•„ìš”

---

## ğŸ–¥ï¸ ì‹¤í–‰ í™˜ê²½

### ë¡œì»¬ (CPU/GPU)

```yaml
# config/config.yaml
misc:
  device: "auto"  # ë˜ëŠ” "cpu", "cuda", "mps"
  
training:
  batch_size: 16  # CPUëŠ” 8, GPUëŠ” 32
```

**ì˜ˆìƒ ì‹œê°„**: CPU 12-16ì‹œê°„, GPU 3-6ì‹œê°„

---

### ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì • (Model Type)

#### 1. Baseline (2-Stage Training)
```yaml
model:
  model_type: "baseline"
training:
  loss_type: "bce"
  num_epochs: 2
self_training:
  enabled: true  # BCE â†’ Self-Training (KLD)
  confidence_threshold: 0.7
  max_iterations: 3
```

#### 2. Focal Loss (í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°)
```yaml
model:
  model_type: "focal_loss"
training:
  loss_type: "focal"
  focal_alpha: 0.25
  focal_gamma: 2.0
  num_epochs: 5
self_training:
  enabled: false
```

#### 3. Self-Training ì—†ì´ (BCEë§Œ)
```yaml
model:
  model_type: "no_self_training"
training:
  loss_type: "bce"
  num_epochs: 5
self_training:
  enabled: false
```

#### 4. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```yaml
model:
  model_type: "quick_test"
training:
  num_epochs: 1
  batch_size: 8
self_training:
  enabled: false
```

**ìƒì„¸ ì„¤ëª…**: `docs/CONFIG.md` ì°¸ì¡°

---

## ğŸ”‘ LLM API ì„¤ì • (ì„ íƒì‚¬í•­)

í‚¤ì›Œë“œ í™•ì¥ì„ ìœ„í•œ OpenAI API ì„¤ì • (ì„ íƒ):

```bash
# 1. API í‚¤ ë°œê¸‰: https://platform.openai.com/
# 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
echo "OPENAI_API_KEY=sk-proj-..." > .env

# 3. Config í™œì„±í™”
# config/config.yaml
silver_labeling:
  llm_expansion:
    enabled: true
    model: "gpt-4o-mini"
    max_calls: 1000  # ë¹„ìš© ì œí•œ

# 4. ì‹¤í–‰
python3 src/silver_labeling/llm_keyword_expansion.py
```

**ìƒì„¸ ì„¤ëª…**: `docs/LLM_KEYWORD_EXPANSION.md` ì°¸ì¡°

---

## ğŸ“Š ë°©ë²•ë¡ 

### 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸

1. **Silver Label ìƒì„±**: í‚¤ì›Œë“œ ë§¤ì¹­(30%) + ì„ë² ë”© ìœ ì‚¬ë„(70%)
2. **Stage 1 (BCE)**: Hard labelë¡œ ì´ˆê¸° í•™ìŠµ (2 epochs)
3. **Stage 2 (KLD)**: Soft pseudo-labelë¡œ self-training (3 iterations)

---

## ğŸ”¬ ì‹¤í—˜ ë° ë¶„ì„

Ablation studyë¥¼ ìœ„í•œ Jupyter Notebook ì œê³µ:

```bash
jupyter notebook notebooks/Ablation_Analysis.ipynb  # ì‹¤í—˜ ë¹„êµ
jupyter notebook notebooks/CaseStudy.ipynb          # ì˜ˆì¸¡ ë¶„ì„
jupyter notebook notebooks/EDA.ipynb                # ë°ì´í„° íƒìƒ‰
```

**ì‹¤í—˜ ì˜ˆì‹œ**:
- Self-training íš¨ê³¼: `self_training.enabled: false`
- ì„ê³„ê°’ ë³€ê²½: `confidence_threshold: 0.8`
- Loss í•¨ìˆ˜ ë¹„êµ: `loss_type: "focal"`

---