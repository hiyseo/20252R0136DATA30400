# Hierarchical Multi-Label Product Classification

**Student ID:** 20252R0136  
**Course:** DATA304 - Machine Learning Applications  
**Project:** Amazon Products Hierarchical Classification with Self-Training

---

## ğŸ“‹ Overview

This project implements a **2-stage hierarchical multi-label classification system** for Amazon product taxonomy:
1. **Stage 1**: Supervised learning with silver labels using BCE loss
2. **Stage 2**: Self-training with soft pseudo-labels using KL Divergence loss

**Key Features:**
- Hybrid top-down silver label generation (keyword + semantic + hierarchy filtering)
- BERT-based encoder with 531-class multi-label classifier
- Soft pseudo-label self-training for semi-supervised learning
- DAG-structured taxonomy with 3 levels (root, mid, leaf)

---

## ğŸ“‚ Project Structure

```
data304_final/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                          # Centralized configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Amazon_products/                 # Original dataset
â”‚   â”‚       â”œâ”€â”€ train/train_corpus.txt       # 29,487 samples
â”‚   â”‚       â”œâ”€â”€ test/test_corpus.txt         # 19,658 samples
â”‚   â”‚       â”œâ”€â”€ classes.txt                  # 531 classes
â”‚   â”‚       â”œâ”€â”€ class_hierarchy.txt          # DAG structure
â”‚   â”‚       â””â”€â”€ class_related_keywords.txt   # Keywords per class
â”‚   â”œâ”€â”€ intermediate/                        # Generated files
â”‚   â”‚   â”œâ”€â”€ train_silver_labels.pkl          # Silver labels (70% coverage)
â”‚   â”‚   â””â”€â”€ test_silver_labels.pkl           # For pseudo-labeling
â”‚   â””â”€â”€ output/                              # Processed outputs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py                # Data loader
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ encoder.py                       # BERT encoder
â”‚   â”‚   â”œâ”€â”€ classifier.py                    # Multi-label classifier
â”‚   â”‚   â””â”€â”€ gnn_classifier.py                # GNN models (GCN, GAT)
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_baseline.py                # Main training script
â”‚   â”‚   â”œâ”€â”€ self_training.py                 # Self-training with soft labels
â”‚   â”‚   â””â”€â”€ loss_functions.py                # BCE, Focal, Asymmetric, KLD
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ predict.py                       # Generate predictions
â”‚   â”‚   â””â”€â”€ dummy_baseline.py                # Simple baseline
â”‚   â”œâ”€â”€ silver_labeling/
â”‚   â”‚   â”œâ”€â”€ generate_silver_labels.py        # Hybrid top-down approach
â”‚   â”‚   â”œâ”€â”€ graph_utils.py                   # Hierarchy analysis
â”‚   â”‚   â””â”€â”€ llm_keyword_expansion.py         # LLM-based expansion
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py                        # Logging utilities
â”‚       â”œâ”€â”€ metrics.py                       # Evaluation metrics
â”‚       â”œâ”€â”€ seed.py                          # Random seed control
â”‚       â””â”€â”€ taxonomy_mapping.py              # Hierarchy utilities
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_labels.py                   # Generate silver labels
â”‚   â”œâ”€â”€ train_with_config.py                 # Config-based training
â”‚   â””â”€â”€ generate_submission.py               # Create Kaggle submission
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb                            # Exploratory data analysis
â”‚   â”œâ”€â”€ Ablation_Analysis.ipynb              # Experiment results
â”‚   â””â”€â”€ CaseStudy.ipynb                      # Error analysis
â”œâ”€â”€ models/                                  # Trained models
â”‚   â””â”€â”€ baseline/
â”‚       â”œâ”€â”€ best_model.pt                    # Final model weights
â”‚       â””â”€â”€ training_history.json            # Loss curves
â”œâ”€â”€ results/                                 # Predictions and visualizations
â”‚   â”œâ”€â”€ predictions/
â”‚   â”‚   â””â”€â”€ baseline_YYYYMMDD_HHMMSS.csv    # Predictions
â”‚   â”œâ”€â”€ submissions/
â”‚   â”‚   â””â”€â”€ 20252R0136_baseline.csv          # Kaggle submission
â”‚   â””â”€â”€ images/                              # Visualizations
â”œâ”€â”€ logs/                                    # Training logs
â”œâ”€â”€ docs/                                    # Documentation
â”‚   â”œâ”€â”€ CONFIG.md                            # Configuration guide
â”‚   â”œâ”€â”€ PIPELINE.md                          # Complete pipeline guide
â”‚   â””â”€â”€ METHODOLOGY.md                       # Detailed methodology
â”œâ”€â”€ requirements.txt                         # Python dependencies
â”œâ”€â”€ run.sh                                   # Quick start script
â””â”€â”€ README.md                                # This file
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Create virtual environment
python3 -m venv data304
source data304/bin/activate  # On macOS/Linux
# data304\Scripts\activate   # On Windows

# Install dependencies
pip install -r requirements.txt
```

**Dependencies:**
- Python 3.10+
- PyTorch 2.0+
- Transformers 4.30+
- sentence-transformers
- NetworkX 3.0+
- scikit-learn, pandas, numpy

### 2. Data Preprocessing (Already Done)

```bash
python3 src/data_preprocessing.py
```

**Output:**
```
âœ“ Loaded 29,487 training samples
âœ“ Loaded 19,658 test samples
âœ“ 531 classes in 3-level DAG hierarchy
âœ“ 6 root nodes, 25 multi-parent nodes
```

### 3. Generate Silver Labels

```bash
python3 scripts/generate_labels.py
```

**Method:** Hybrid top-down approach
- **Score**: `0.3 Ã— keyword_matching + 0.7 Ã— semantic_similarity`
- **Filtering**: Level-by-level hierarchy filtering (root â†’ mid â†’ leaf)
- **Thresholds**: Ï„â‚€=0.105, Ï„â‚=0.15, Ï„â‚‚=0.1

**Output:**
```
data/intermediate/
â”œâ”€â”€ train_silver_labels.pkl    # 70% coverage, 3.25 labels/sample
â””â”€â”€ test_silver_labels.pkl     # For pseudo-labeling
```

### 4. Train Baseline Model

```bash
# Config-based training (recommended)
python3 scripts/train_with_config.py

# Or direct command
python3 src/training/train_baseline.py \
  --model_type baseline \
  --num_epochs 2 \
  --use_self_training
```

**Training Process:**
```
Stage 1: BCE Initialization (2 epochs)
  â””â”€ Train on silver labels with BCE loss
  â””â”€ Purpose: Initialize model for pseudo-labeling

Stage 2: Self-Training (3 iterations)
  â””â”€ Generate soft pseudo-labels (confidence â‰¥ 0.7)
  â””â”€ Train with KLD loss on labeled + pseudo-labeled data
  â””â”€ Purpose: Refine model with unlabeled data
```

**Expected time:** 3-4 hours on V100 GPU

**Output:**
```
models/baseline/
â”œâ”€â”€ best_model.pt              # Final trained model
â”œâ”€â”€ training_history.json      # Loss curves
â””â”€â”€ checkpoint_epoch_*.pt      # Intermediate checkpoints
```

### 5. Generate Predictions

```bash
python3 src/inference/predict.py \
  --model_path models/baseline/best_model.pt \
  --model_name baseline
```

**Output:**
```
results/predictions/
â”œâ”€â”€ baseline_20251213_143022.pkl    # For analysis
â””â”€â”€ baseline_20251213_143022.csv    # For submission
```

### 6. Create Submission

```bash
python3 scripts/generate_submission.py \
  --predictions results/predictions/baseline_*.csv \
  --output results/submissions/20252R0136_baseline.csv
```

**Format:**
```csv
20252R0136,pid
20252R0136,50 125 328
20252R0136,12 89 245 401
...
```

---

## ğŸ“Š Baseline Methodology

### Stage 0: Silver Label Generation

**Mathematical Formulation:**

$$s(x_i, c_j) = 0.3 \cdot \frac{|\text{tokens}(x_i) \cap K_{c_j}|}{|K_{c_j}|} + 0.7 \cdot \cos(\phi(x_i), \phi(c_j))$$

where:
- $\phi(\cdot)$ = sentence-transformers embedding (all-mpnet-base-v2)
- $K_{c_j}$ = keywords for class $c_j$

**Top-Down Filtering:**
```
For each level â„“ âˆˆ {0, 1, 2}:
  1. Select: Selected_â„“ = {c : s(x, c) â‰¥ Ï„_â„“}
  2. Allow children: Allowed_{â„“+1} = {c : parent(c) âˆˆ Selected_â„“}
```

### Stage 1: Supervised Learning (BCE)

**Loss Function:**

$$L_{\text{BCE}}(x, y) = -\frac{1}{k}\sum_{j=1}^{k} [y_j \log p_j + (1-y_j) \log(1-p_j)]$$

where $y \in \{0, 1\}^k$ are binary silver labels.

### Stage 2: Self-Training (KLD)

**Pseudo-Label Generation:**

$$\tilde{p} = \sigma(f_\theta(x)) \quad \text{if} \quad \max(\tilde{p}) \geq 0.7$$

**Loss Function:**

$$L_{\text{KLD}}(x, \tilde{p}) = \frac{1}{k}\sum_{j=1}^{k} \tilde{p}_j \log\frac{\tilde{p}_j}{p_j}$$

where $\tilde{p} \in [0, 1]^k$ are soft pseudo-labels.

**Key Difference:**
- BCE uses **hard labels** (0/1) â†’ Forces binary decisions
- KLD uses **soft labels** (0~1) â†’ Preserves uncertainty

---

## âš™ï¸ Configuration

Edit `config/config.yaml` to change settings:

```yaml
model:
  model_type: "baseline"          # Experiment identifier
  model_name: "bert-base-uncased"

training:
  batch_size: 16
  num_epochs: 2                   # Stage 1 initialization
  learning_rate: 2.0e-5
  loss_type: "bce"                # Stage 1: BCE, Stage 2: KLD (auto)

self_training:
  enabled: true                   # Enable 2-stage training
  confidence_threshold: 0.7
  max_iterations: 3

output:
  output_dir: "models/{model_type}"  # Auto-resolved placeholder
```

See `docs/CONFIG.md` for detailed configuration guide.

---

## ğŸ“ˆ Performance

### Silver Label Statistics
- **Coverage**: 70.0% (20,640/29,487 training samples)
- **Avg labels/sample**: 3.25
- **Class usage**: 445/531 (83.8%)

### Model Architecture
- **Encoder**: BERT-base-uncased (109.9M parameters)
- **Classifier**: Linear(768 â†’ 531)
- **Total parameters**: ~110M

### Expected Training Performance
- **Stage 1 BCE loss**: 0.60-0.65
- **Stage 2 KLD loss**: 0.35-0.40
- **Pseudo-label coverage**: 75-85% of test set

---

## ğŸ› ï¸ Advanced Usage

### Ablation Studies

**Experiment 1: No Self-Training**
```yaml
# config.yaml
model:
  model_type: "no_self_training"
self_training:
  enabled: false
training:
  num_epochs: 5
```

**Experiment 2: Focal Loss**
```yaml
model:
  model_type: "focal_loss"
training:
  loss_type: "focal"
  focal_alpha: 0.25
  focal_gamma: 2.0
self_training:
  enabled: false
```

### AWS SageMaker Deployment

```bash
# SSH to SageMaker instance
ssh -i your-key.pem ubuntu@your-instance

# Clone and setup
git clone https://github.com/hiyseo/20252R0136DATA30400.git
cd 20252R0136DATA30400
source data304/bin/activate

# Run pipeline
python3 scripts/generate_labels.py
python3 scripts/train_with_config.py
python3 src/inference/predict.py \
  --model_path models/baseline/best_model.pt \
  --model_name baseline
```

---

## ğŸ“š Documentation

- **`docs/CONFIG.md`**: Configuration parameters and examples
- **`docs/PIPELINE.md`**: Complete step-by-step pipeline guide
- **`docs/METHODOLOGY.md`**: Detailed methodology and mathematical formulation

---

## ğŸ” Analysis

Run Jupyter notebooks for detailed analysis:

```bash
jupyter notebook notebooks/EDA.ipynb              # Dataset exploration
jupyter notebook notebooks/Ablation_Analysis.ipynb  # Experiment comparison
jupyter notebook notebooks/CaseStudy.ipynb         # Error analysis
```

---

## ğŸ› Troubleshooting

### CUDA Out of Memory
```yaml
# config.yaml
training:
  batch_size: 8  # Reduce from 16
data:
  max_length: 64  # Reduce from 128
```

### Training Too Slow
```yaml
training:
  num_epochs: 2  # Reduce epochs
self_training:
  max_iterations: 2  # Reduce iterations
```

### Low Coverage
```yaml
silver_labeling:
  topdown_threshold: 0.1  # Lower threshold (was 0.15)
  min_confidence: 0.05    # Lower confidence (was 0.1)
```

---

## âš–ï¸ License

This project is for academic purposes only (DATA304 Course Project).
